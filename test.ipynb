{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ed56fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6262fe54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a391126",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "mnist = torchvision.datasets.MNIST(root=\"/media/miju_chowdhury/Miju/Datasets\", download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "742632e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = mnist._load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d309d9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([60000, 28, 28]), torch.Size([60000]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ac1c3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ccb565a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'tensor(1)')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = random.randint(0,x.shape[0])\n",
    "plt.imshow(x[idx])\n",
    "plt.title(y[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58e3f375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Tensor, torch.Tensor)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x), type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb79848f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28, 28])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b17b963",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCNN(nn.Module):\n",
    "    def __init__(self, n=784, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(in_features=n, out_features=100)\n",
    "        self.fc2 = nn.Linear(in_features=100, out_features=50)\n",
    "        self.fc3 = nn.Linear(in_features=50, out_features=40)\n",
    "        self.output_layer = nn.Linear(in_features=50, out_features=num_classes)\n",
    "    def forward(self, x):\n",
    "        x1 = self.fc1(x)\n",
    "        x2 = self.fc2(x1)\n",
    "        x3 = self.fc3(x2)\n",
    "        return self.output_layer(x3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a75c40cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self, in_feaure=784, num_classes = 10):\n",
    "        super().__init__()\n",
    "        self.seq = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=in_feaure, out_features=100),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(in_features=100, out_features=80),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(in_features=80, out_features=50),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(in_features=50, out_features=num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.seq(x)\n",
    "model = MyModel(in_feaure=784)\n",
    "# list(model.parameters()).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "32c538a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 784])\n",
      "torch.Size([100])\n",
      "torch.Size([80, 100])\n",
      "torch.Size([80])\n",
      "torch.Size([50, 80])\n",
      "torch.Size([50])\n",
      "torch.Size([10, 50])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for parameters in model.parameters():\n",
    "    print(parameters.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef5c4880",
   "metadata": {},
   "outputs": [],
   "source": [
    "xa = x[0].type(torch.float32).to(device)\n",
    "xa = xa.unsqueeze(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5376960f",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxa\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.13/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.13/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[12], line 16\u001b[0m, in \u001b[0;36mMyModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseq\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.13/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.13/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.local/lib/python3.13/site-packages/torch/nn/modules/container.py:240\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 240\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.13/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.13/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.local/lib/python3.13/site-packages/torch/nn/modules/linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)"
     ]
    }
   ],
   "source": [
    "model(xa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f9489d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.4195,  2.2211,  3.0486,  4.5452,  1.4578,  2.6676, -2.8623,  5.4094,\n",
      "         -1.2245,  1.7211]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "with torch.inference_mode():\n",
    "    print(model(xa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406e4dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = torchvision.datasets.MNIST(root=\"/media/miju_chowdhury/Miju/Datasets\", download=True, train=True)._load_data()\n",
    "x_test, y_test = torchvision.datasets.MNIST(root=\"/media/miju_chowdhury/Miju/Datasets\", download=True, train=False)._load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cbe12a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([60000, 28, 28]),\n",
       " torch.Size([60000]),\n",
       " torch.Size([10000, 28, 28]),\n",
       " torch.Size([10000]))"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6fd39d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.uint8, torch.int64)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.dtype, y_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e0bfa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train[:10000].type(torch.float32)\n",
    "y_train = y_train[:10000].type(torch.LongTensor)\n",
    "\n",
    "x_test = x_test.type(torch.float32)\n",
    "y_test = y_test.type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edca1afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel(in_feaure=784).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c575036",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(params=model.parameters(),\n",
    "                             lr=1e-5)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d60a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61d0e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "batch_size = 64\n",
    "\n",
    "num_train = x_train.shape[0]\n",
    "print(num_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9cccb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(images, labels):\n",
    "    model.train()\n",
    "    losses=[]\n",
    "    num_train = images.shape[0]\n",
    "    for i in range(0, num_train, batch_size):\n",
    "        x = images[i:i+batch_size].to(device)\n",
    "        y = labels[i:i+batch_size].to(device)\n",
    "\n",
    "        y_pred = model(x)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "    return np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24de35a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_epoch(images, labels):\n",
    "    model.eval()\n",
    "    losses=[]\n",
    "    num_val = x_test.shape[0]\n",
    "    for i in range(0, num_val, batch_size):\n",
    "        x = images[i:i+batch_size].to(device)\n",
    "        y = labels[i:i+batch_size].to(device)\n",
    "\n",
    "        with torch.inference_mode():\n",
    "            y_preds = model(x)\n",
    "        loss = loss_fn(y_preds, y)\n",
    "\n",
    "        losses.append(loss.item())\n",
    "    return np.mean(losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32dfc60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1/10\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: unspecified launch failure\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[143], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     val_loss \u001b[38;5;241m=\u001b[39m validation_epoch(images\u001b[38;5;241m=\u001b[39mx_test, labels\u001b[38;5;241m=\u001b[39my_test)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain Loss : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m0.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Val Loss : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m0.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[141], line 6\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(images, labels)\u001b[0m\n\u001b[1;32m      4\u001b[0m num_train \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, num_train, batch_size):\n\u001b[0;32m----> 6\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mimages\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m:\u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     y \u001b[38;5;241m=\u001b[39m labels[i:i\u001b[38;5;241m+\u001b[39mbatch_size]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      9\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m model(x)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: unspecified launch failure\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch : {epoch+1}/{epochs}\")\n",
    "    train_loss = train_epoch(images=x_train, labels=y_train)\n",
    "    val_loss = validation_epoch(images=x_test, labels=y_test)\n",
    "    print(f\"Train Loss : {train_loss:0.4f} | Val Loss : {val_loss:0.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d05651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.7.0+cu126'"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ede34ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue May 27 22:42:50 2025       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.247.01             Driver Version: 535.247.01   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce MX130           Off | 00000000:06:00.0 Off |                  N/A |\n",
      "| N/A   64C    P0              N/A / 200W |     80MiB /  2048MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      2306      G   /usr/lib/xorg/Xorg                            2MiB |\n",
      "|    0   N/A  N/A      2792    C+G   /usr/bin/anydesk                              2MiB |\n",
      "|    0   N/A  N/A      5203      C   /usr/bin/python                              69MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
